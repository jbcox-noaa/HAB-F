{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7875340c-d0cc-4e37-8701-8b135595e87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef83716-b88f-4a9b-9cbc-0eb470844b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"glrl-hab-data.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1a07f1b-77c8-4893-a7b4-66e0274b9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filename = \"Grid_search_oversample/3day_5px_0.1pm/training_data_balanced_PACE.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5182a96-da50-4365-bdc0-6cfe49bdf01c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 290 entries from Grid_search_oversample/3day_5px_0.1pm/training_data_balanced_PACE.npy\n",
      "First entry tuple length: 4\n",
      "Tuple contents/types: [<class 'str'>, <class 'str'>, <class 'tuple'>, <class 'numpy.ndarray'>]\n",
      "Lengths/shapes of elements:\n",
      "  Element 0: PACE_OCI.20240902T180931.L2.OC_AOP.V3_0.nc (type <class 'str'>)\n",
      "  Element 1: 2024.2 (type <class 'str'>)\n",
      "  Element 2: ('2024.2', Timestamp('2024-09-02 18:09:31+0000', tz='UTC'), 41.71703333, -83.41671667, 30.28, 0.43, 481.58) (type <class 'tuple'>)\n",
      "  Element 3: numpy array with shape (4300,)\n",
      "patch_flat length: 4300\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the training data\n",
    "try:\n",
    "    data = np.load(training_data_filename, allow_pickle=True)\n",
    "    print(f\"Loaded {len(data)} entries from {training_data_filename}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"{training_data_filename} not found in the current directory.\")\n",
    "\n",
    "# Inspect first entry to understand tuple structure\n",
    "first_entry = data[60]\n",
    "print(f\"First entry tuple length: {len(first_entry)}\")\n",
    "print(f\"Tuple contents/types: {[type(x) for x in first_entry]}\")\n",
    "print(f\"Lengths/shapes of elements:\")\n",
    "for idx, elem in enumerate(first_entry):\n",
    "    if isinstance(elem, np.ndarray):\n",
    "        print(f\"  Element {idx}: numpy array with shape {elem.shape}\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"  Element {idx}: {elem} (type {type(elem)})\")\n",
    "        except:\n",
    "            print(f\"  Element {idx}: type {type(elem)}\")\n",
    "\n",
    "# Assume structure is (row_index, labels_array, patch_flat_array)\n",
    "# Adjust these indices if different.\n",
    "patch_flat = first_entry[3]\n",
    "print(f\"patch_flat length: {patch_flat.size}\")\n",
    "\n",
    "# Example inference (only if patch is square and c known):\n",
    "c = 172\n",
    "spatial_pixels = patch_flat.size // c\n",
    "if spatial_pixels * c != patch_flat.size:\n",
    "    raise ValueError(\"Flat size not divisible by c; adjust c or patch shape.\")\n",
    "side = int(np.sqrt(spatial_pixels))\n",
    "if side * side != spatial_pixels:\n",
    "    raise ValueError(\"Spatial dimension not square; set h and w manually.\")\n",
    "h, w = side, side\n",
    "\n",
    "# Ensure patch_flat can reshape to (h, w, c)\n",
    "if h is None or w is None or c is None:\n",
    "    raise ValueError(\"Please set h, w, c to the correct patch dimensions before plotting.\")\n",
    "\n",
    "if patch_flat.size != h * w * c:\n",
    "    raise ValueError(f\"patch_flat size {patch_flat.size} does not match h*w*c = {h*w*c}\")\n",
    "\n",
    "# Reshape and plot RGB for the first entry\n",
    "patch = patch_flat.reshape((h, w, c))\n",
    "\n",
    "red_idx = 105\n",
    "green_idx = 75\n",
    "blue_idx = 48 \n",
    "\n",
    "# after reshaping patch_flat → patch (h, w, c) and selecting R,G,B indices:\n",
    "red = patch[:,:,red_idx]\n",
    "green = patch[:,:,green_idx]\n",
    "blue = patch[:,:,blue_idx]\n",
    "rgb = np.stack([red, green, blue], axis=-1)  # reflectance array\n",
    "\n",
    "# Normalize using fixed vmax:\n",
    "vmax = 0.05  # adjust if your scene reflectance peaks lower/higher\n",
    "rgb_norm = rgb / vmax\n",
    "rgb_norm = np.clip(rgb_norm, 0, 1)\n",
    "\n",
    "# Apply gamma correction:\n",
    "gamma = 1/2.2  # or 1/1.5 for more brightness\n",
    "rgb_plot = np.clip(rgb_norm ** gamma, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(rgb_plot, origin='lower')\n",
    "plt.axis('off')\n",
    "plt.title(\"Brightened True Color\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae98430f-fe13-46d6-8f9d-d1c70519c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_filename = \"Grid_search3/3day_3px_1pm/training_data_PACE.npy\"\n",
    "# Load the training data\n",
    "try:\n",
    "    data = np.load(training_data_filename, allow_pickle=True)\n",
    "    print(f\"Loaded {len(data)} entries from {training_data_filename}\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"{training_data_filename} not found in the current directory.\")\n",
    "\n",
    "# Inspect first entry to understand tuple structure\n",
    "first_entry = data[0]\n",
    "print(f\"First entry tuple length: {len(first_entry)}\")\n",
    "print(f\"Tuple contents/types: {[type(x) for x in first_entry]}\")\n",
    "print(f\"Lengths/shapes of elements:\")\n",
    "for idx, elem in enumerate(first_entry):\n",
    "    if isinstance(elem, np.ndarray):\n",
    "        print(f\"  Element {idx}: numpy array with shape {elem.shape}\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"  Element {idx}: {elem} (type {type(elem)})\")\n",
    "        except:\n",
    "            print(f\"  Element {idx}: type {type(elem)}\")\n",
    "\n",
    "# Assume structure is (row_index, labels_array, patch_flat_array)\n",
    "# Adjust these indices if different.\n",
    "patch_flat = first_entry[3]\n",
    "print(f\"patch_flat length: {patch_flat.size}\")\n",
    "\n",
    "# Example inference (only if patch is square and c known):\n",
    "c = 172\n",
    "spatial_pixels = patch_flat.size // c\n",
    "if spatial_pixels * c != patch_flat.size:\n",
    "    raise ValueError(\"Flat size not divisible by c; adjust c or patch shape.\")\n",
    "side = int(np.sqrt(spatial_pixels))\n",
    "if side * side != spatial_pixels:\n",
    "    raise ValueError(\"Spatial dimension not square; set h and w manually.\")\n",
    "h, w = side, side\n",
    "\n",
    "# Ensure patch_flat can reshape to (h, w, c)\n",
    "if h is None or w is None or c is None:\n",
    "    raise ValueError(\"Please set h, w, c to the correct patch dimensions before plotting.\")\n",
    "\n",
    "if patch_flat.size != h * w * c:\n",
    "    raise ValueError(f\"patch_flat size {patch_flat.size} does not match h*w*c = {h*w*c}\")\n",
    "\n",
    "# Reshape and plot RGB for the first entry\n",
    "patch = patch_flat.reshape((h, w, c))\n",
    "\n",
    "red_idx = 105\n",
    "green_idx = 75\n",
    "blue_idx = 48 \n",
    "\n",
    "# after reshaping patch_flat → patch (h, w, c) and selecting R,G,B indices:\n",
    "red = patch[:,:,red_idx]\n",
    "green = patch[:,:,green_idx]\n",
    "blue = patch[:,:,blue_idx]\n",
    "rgb = np.stack([red, green, blue], axis=-1)  # reflectance array\n",
    "\n",
    "# Normalize using fixed vmax:\n",
    "vmax = 0.05  # adjust if your scene reflectance peaks lower/higher\n",
    "rgb_norm = rgb / vmax\n",
    "rgb_norm = np.clip(rgb_norm, 0, 1)\n",
    "\n",
    "# Apply gamma correction:\n",
    "gamma = 1/2.2  # or 1/1.5 for more brightness\n",
    "rgb_plot = np.clip(rgb_norm ** gamma, 0, 1)\n",
    "\n",
    "plt.figure(figsize=(4,4))\n",
    "plt.imshow(rgb_plot, origin='lower')\n",
    "plt.axis('off')\n",
    "plt.title(\"Brightened True Color\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4410d5-7482-45f7-81f2-b7f6e42c4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in data:\n",
    "    patch_len = len(entry[3])\n",
    "    print(patch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac21de7-af0d-4a4f-949e-910b3eced72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd878022-7c16-48b6-a5f0-16c1edf65384",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "for entry in data:\n",
    "    dates.append(pd.to_datetime(entry[2][1], utc = True))\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71294a2b-76d2-4e95-b92e-02950d235e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.dates as mdates\n",
    "\n",
    "date_counts = pd.Series(dates).value_counts().sort_index()\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.bar(date_counts.index, date_counts.values, width=0.9)\n",
    "\n",
    "# Format the x-axis\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=15))  # tick every 7 days\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))  # format tick labels\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Count\")\n",
    "ax.set_title(\"Histogram of Timestamps by Day\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eddadd8-87a6-4a68-9237-bd71689e305b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe40a738-fc2a-4922-bcfc-a7a045a74210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Subset to only include timestamps from 2024 and onward\n",
    "df_recent = df[df['timestamp'] >= pd.Timestamp('2024-01-01')].copy()\n",
    "\n",
    "# 2. Normalize to date (for grouping by day)\n",
    "df_recent['date'] = df_recent['timestamp'].dt.normalize()\n",
    "\n",
    "# 3. Count samples per day\n",
    "daily_counts = df_recent['date'].value_counts().sort_index()\n",
    "\n",
    "# 4. Plot the histogram\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.bar(daily_counts.index, daily_counts.values, width=2.9)\n",
    "\n",
    "# Format x-axis to show one tick every 7 days\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=30))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Sample Count\")\n",
    "ax.set_title(\"Number of Samples per Day (2024 and After)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a72303c-3327-4690-9036-a2fa462bfd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "# Filter to 2024-06-01 through 2024-10-15\n",
    "df_plot = df[(df['timestamp'] >= pd.Timestamp('2024-06-01')) & \n",
    "             (df['timestamp'] <= pd.Timestamp('2024-10-20'))].copy()\n",
    "\n",
    "# Filter out non-positive values\n",
    "df_plot = df_plot[df_plot['particulate_microcystin'] > 0].copy()\n",
    "\n",
    "# Compute log10\n",
    "df_plot['log_particulate_microcystin'] = np.log10(df_plot['particulate_microcystin'])\n",
    "\n",
    "# Create scatter plot with increased height\n",
    "fig, ax = plt.subplots(figsize=(10, 8))  # 3x taller\n",
    "\n",
    "ax.scatter(\n",
    "    df_plot['timestamp'],\n",
    "    df_plot['log_particulate_microcystin'],\n",
    "    color='blue',\n",
    "    s=10,\n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Set y-axis range to -1 to 1\n",
    "ax.set_ylim(-2, 1)\n",
    "\n",
    "# Format x-axis\n",
    "ax.xaxis.set_major_locator(mdates.DayLocator(interval=14))\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add horizontal lines at integer log levels (only -1, 0, 1)\n",
    "for y in range(-1, 2):  # -1, 0, 1\n",
    "    ax.axhline(y=y, color='gray', linestyle='--', linewidth=0.5, alpha=0.6)\n",
    "\n",
    "# Labels\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"log₁₀(Particulate Microcystin)\")\n",
    "ax.set_title(\"Scatter Plot of log₁₀ Particulate Microcystin (2024-06 to 2024-10)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cd335c-f953-40ce-a696-effa21ca8ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "# Ensure timestamp is datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Extract date only\n",
    "df['date'] = df['timestamp'].dt.normalize()\n",
    "\n",
    "# Filter to 2024 and desired date range (June 19 to Oct 10)\n",
    "df_filtered = df[\n",
    "    (df['timestamp'].dt.year == 2024) &\n",
    "    (df['timestamp'].dt.month * 100 + df['timestamp'].dt.day >= 600) &\n",
    "    (df['timestamp'].dt.month * 100 + df['timestamp'].dt.day <= 1100)\n",
    "]\n",
    "\n",
    "# Drop rows where particulate_microcystin is <= 0 (log undefined)\n",
    "df_filtered = df_filtered[df_filtered['particulate_microcystin'] > 0].copy()\n",
    "\n",
    "# Take log10\n",
    "df_filtered['log_particulate_microcystin'] = np.log10(df_filtered['particulate_microcystin'])\n",
    "\n",
    "# Group into list of log-values per date\n",
    "grouped = df_filtered.groupby('date')['log_particulate_microcystin'].apply(list)\n",
    "\n",
    "# Convert to lists for plotting\n",
    "dates = grouped.index\n",
    "data = grouped.values\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "ax.boxplot(data, positions=range(len(dates)), widths=0.6, showfliers=True)\n",
    "\n",
    "# Format x-axis\n",
    "ax.set_xticks(range(len(dates)))\n",
    "ax.set_xticklabels([d.strftime('%Y-%m-%d') for d in dates], rotation=45, ha='right')\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Log10 Particulate Microcystin\")\n",
    "ax.set_title(\"Daily Boxplots (log10) of Particulate Microcystin (2024-06-19 to 2024-10-10)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76dc6366-e24a-4158-ae9e-8290164dc52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('training_data_PACE.npy', np.array(data, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7d6ba5-5f98-4d98-9558-14b641de7378",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for entry in data:\n",
    "    \n",
    "    for j in range(i, len(df)):\n",
    "        \n",
    "        labels = entry[2]\n",
    "        print(j)\n",
    "        print(pd.to_datetime(labels[1], utc = True))\n",
    "        print(pd.to_datetime(df.loc[j, 'timestamp'], utc = True))\n",
    "        print()\n",
    "        if labels[0] == df.loc[j, 'station_name'] and \\\n",
    "            pd.to_datetime(labels[1], utc = True) == pd.to_datetime(df.loc[j, 'timestamp'], utc = True):\n",
    "                print(\"FOUND ONE\")\n",
    "                labels = (labels[0], labels[1], labels[2], labels[3], labels[4], df.loc[j, 'dissolved_microcystin'], labels[5])\n",
    "                i = j\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c845cb22-dd6c-4150-bc2b-de728ab9c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae204e-0f6a-4702-a6fe-23e587a60477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b3b3d-0295-4dbc-b4f2-e1ee7a98b778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff87854-fc10-4aa2-afc7-0296859be4cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c2a3e-3b94-4194-b83e-5d3ab65d4afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def crop_and_clean_array(data):\n",
    "    cleaned_entries = []\n",
    "\n",
    "    for entry in data:\n",
    "        granule_name, site_code, metadata, patch = entry\n",
    "\n",
    "        if patch.size == 4300:  # 8x8x11\n",
    "            patch_3d = patch.reshape(5, 5, 172)\n",
    "            # Crop center 2x2 pixels (from rows 3:5, cols 3:5)\n",
    "            cropped = patch_3d[1:3, 1:3, :]  # shape (2, 2, 11)\n",
    "            reshaped = cropped.reshape(-1)  # Flatten to (44,)\n",
    "\n",
    "            # Check NaN status per pixel\n",
    "            pixel_nans = np.isnan(cropped.reshape(1, 172))  # (4, 11)\n",
    "            pixel_all_nan = np.all(pixel_nans, axis=1)     # (4,)\n",
    "\n",
    "            if np.sum(~pixel_all_nan) >= 1:\n",
    "                cleaned_entries.append([granule_name, site_code, metadata, reshaped])\n",
    "\n",
    "        elif patch.size == 1548:  # already 2x2x11\n",
    "            reshaped = patch.reshape(9, 172)\n",
    "            pixel_all_nan = np.all(np.isnan(reshaped), axis=1)\n",
    "\n",
    "            if np.sum(~pixel_all_nan) >= 2:\n",
    "                cleaned_entries.append(entry)\n",
    "\n",
    "        else:\n",
    "            print(f\"Skipping entry with unexpected patch size: {patch.size}\")\n",
    "\n",
    "    return np.array(cleaned_entries, dtype=object)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9ac13-97b0-4139-bd76-5b530e295d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = crop_and_clean_array(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63644002-e29d-4486-8f1c-b71f7aa0b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e59dc4-fb8f-4f6f-807b-fe58643b9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_patch_pixels(data):\n",
    "    final_entries = []\n",
    "\n",
    "    for entry in data:\n",
    "        granule_name, site_code, metadata, patch = entry\n",
    "\n",
    "        try:\n",
    "            reshaped = patch.reshape(4, 11)  # 2x2 pixels, 11 channels\n",
    "            mean_pixel = np.nanmean(reshaped, axis=0)  # shape (11,)\n",
    "            final_entries.append([granule_name, site_code, metadata, mean_pixel])\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process entry {granule_name}: {e}\")\n",
    "\n",
    "    return np.array(final_entries, dtype=object)\n",
    "data = average_patch_pixels(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e028a-a65a-4fd0-8321-be7ef1767549",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'training_data_PACE_cropped', np.array(data, dtype=object))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59750e1c-06e2-4ff6-9a98-f74bc6fca118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels arrays, replacing NaN with 0\n",
    "partic_list = []\n",
    "for entry in data:\n",
    "    labels = entry[2]  # (particulate)\n",
    "    if labels is not None and len(labels) >= 2:\n",
    "        partic_val = labels[4] if not np.isnan(labels[4]) else 0.01\n",
    "        if partic_val == 0: partic_val = 0.01\n",
    "        partic_list.append(partic_val)\n",
    "\n",
    "partic = np.array(partic_list, dtype=float)\n",
    "\n",
    "# Only values > 0\n",
    "partic_positive = partic[partic > -1]\n",
    "\n",
    "print(f\"Particulate: total={len(partic)}, >0 count={len(partic_positive)}\")\n",
    "\n",
    "# 1) Histogram with log-scaled x-axis and log-spaced bins\n",
    "def plot_log_histogram(values, title):\n",
    "    # Determine bin edges in log space\n",
    "    min_val = values.min()\n",
    "    max_val = values.max()\n",
    "    # Avoid issues if min_val is 0 (we have filtered >0)\n",
    "    bins = np.logspace(np.log10(min_val), np.log10(max_val), 50)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(values, bins=bins)\n",
    "    plt.xscale('log')\n",
    "    plt.title(title + \" (log-scaled bins)\")\n",
    "    plt.xlabel(\"Value (log scale)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True, which='both', ls='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# 2) Histogram of log-transformed values (linear bins on log values)\n",
    "def plot_hist_log_transformed(values, title):\n",
    "    log_vals = np.log10(values)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(log_vals, bins=30)\n",
    "    plt.title(title + \" (histogram of log10(values))\")\n",
    "    plt.xlabel(\"log10(Value)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True, ls='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# 3) Boxplot of log-transformed values\n",
    "def plot_boxplot_log(values, title):\n",
    "    log_vals = np.log10(values)\n",
    "    plt.figure(figsize=(4, 6))\n",
    "    plt.boxplot(log_vals, vert=True)\n",
    "    plt.title(title + \" (boxplot of log10(values))\")\n",
    "    plt.ylabel(\"log10(Value)\")\n",
    "    plt.grid(True, ls='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# 4) Empirical CDF (on log scale)\n",
    "def plot_ecdf(values, title):\n",
    "    sorted_vals = np.sort(values)\n",
    "    n = len(sorted_vals)\n",
    "    ecdf = np.arange(1, n + 1) / n\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(sorted_vals, ecdf)\n",
    "    plt.xscale('log')\n",
    "    plt.title(title + \" CDF (x-axis log scale)\")\n",
    "    plt.xlabel(\"Value (log scale)\")\n",
    "    plt.ylabel(\"ECDF\")\n",
    "    plt.grid(True, which='both', ls='--', alpha=0.5)\n",
    "    plt.show()\n",
    "\n",
    "# Plot for particulate_microcystin > 0\n",
    "plot_log_histogram(partic_positive, \"Particulate Microcystin\")\n",
    "plot_hist_log_transformed(partic_positive, \"Particulate Microcystin\")\n",
    "plot_boxplot_log(partic_positive, \"Particulate Microcystin\")\n",
    "plot_ecdf(partic_positive, \"Particulate Microcystin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713c5c06-a1fb-4c77-a771-01fe0e82d49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bfab8f-2550-49b9-8559-ece2639a5ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest = pd.to_datetime(\"2025-1-1\", utc = True)\n",
    "\n",
    "for i in range(len(data)):\n",
    "    labels = data[i][2]\n",
    "    date = pd.to_datetime(labels[1], utc = True)\n",
    "    if date < earliest: \n",
    "        print(f\"{i} - {date} earlier than {earliest}\")\n",
    "        earliest = date\n",
    "\n",
    "print(earliest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836726a3-3a03-49e9-a15b-ae2862349ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for i in range(len(data)):\n",
    "    labels = data[i][1]\n",
    "    for idx, row in df.iterrows():\n",
    "        if pd.to_datetime(labels[1]) == pd.to_datetime(row.get(\"timestamp\")) and \\\n",
    "            labels[2] == row.get(\"lat\") and \\\n",
    "            labels[3] == row.get(\"lon\"):\n",
    "                label_dict[i] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4600ad0-c199-4a11-839f-e49dabe8514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a092699-c9f5-46e4-a735-dca862d2224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for i in range(len(df)):\n",
    "    if i not in label_dict.values():\n",
    "        total = total + 1\n",
    "\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba827c1a-ebdd-4c30-970d-f90a8fa46aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df) - total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5074021-93ac-4faa-8e39-2f321609db67",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661e6621-17b8-4a7d-ab44-f0101940dafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "value_counts = Counter(label_dict.values())\n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168db1d1-9cd2-4db8-9b89-4ca80cbde651",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.station_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fbe2404-399f-4e14-b33f-485c933a86fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dce71e9-98ea-417a-8faf-1a56fd3e9b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
